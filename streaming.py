"""
å®Œå…¨ç‰ˆ AITuberã‚·ã‚¹ãƒ†ãƒ  v2.2 - 4ã‚¨ãƒ³ã‚¸ãƒ³å®Œå…¨å¯¾å¿œç‰ˆï¼ˆæ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰
Google AI Studioæ–°éŸ³å£°åˆæˆï¼ˆ2025å¹´5æœˆè¿½åŠ ï¼‰+ Avis Speech + VOICEVOX + ã‚·ã‚¹ãƒ†ãƒ TTS

é‡è¦ãªè¿½åŠ :
- Google AI Studio æ–°éŸ³å£°åˆæˆAPIï¼ˆ2025å¹´5æœˆè¿½åŠ ï¼‰ã«å®Œå…¨å¯¾å¿œ
- æ—¢å­˜ã®å…¨æ©Ÿèƒ½ã‚’ç¶­æŒãƒ»æ‹¡å¼µï¼ˆæ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰
- 4ã¤ã®éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³å®Œå…¨çµ±åˆ
- å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’4ã‚¨ãƒ³ã‚¸ãƒ³å¯¾å¿œã§å®Œå…¨å®Ÿè£…
- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’4ã‚¨ãƒ³ã‚¸ãƒ³ã«å®Œå…¨æ‹¡å¼µ

æ©Ÿèƒ½ï¼ˆå…¨ã¦å®Œå…¨å®Ÿè£…ãƒ»æ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰:
- 4ã¤ã®éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³çµ±åˆï¼ˆæœ€æ–°æŠ€è¡“å®Œå…¨å¯¾å¿œï¼‰
- å®Œå…¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
- è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä½œæˆãƒ»ç·¨é›†ãƒ»ç®¡ç†ãƒ»è¤‡è£½ãƒ»å‰Šé™¤
- å®Œå…¨ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½
- YouTubeãƒ©ã‚¤ãƒ–å®Œå…¨é€£æº
- AIå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨å®Ÿè£…
- å®Œå…¨ç„¡æ–™ã€œãƒ—ãƒ­å“è³ªã¾ã§å…¨å¯¾å¿œ
"""

from config import ConfigManager
from character_manager import CharacterManager
from audio_manager import VoiceEngineManager, AudioPlayer
from communication_logger import CommunicationLogger # è¿½åŠ 

import tkinter as tk
from tkinter import ttk, messagebox, filedialog, simpledialog
from google import genai # å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¨å¥¨
from google.genai import types # å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¨å¥¨
#import google.generativeai as genai # ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
import requests
import asyncio
import json
import time
import os
import threading
import logging
import uuid
import webbrowser
import tempfile
#import subprocess
import platform
from datetime import datetime
from pathlib import Path
import aiohttp
#import urllib.parse
import base64
import wave # wave ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import re # æ­£è¦è¡¨ç¾ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# import json # JSONãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (macOSãƒ‡ãƒã‚¤ã‚¹å–å¾—ã§ä½¿ç”¨) # é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆãªã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
import csv
import traceback # ã‚¨ãƒ©ãƒ¼è¿½è·¡ç”¨ã«è¿½åŠ 



# AITuberã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  v2.1ï¼ˆä¿®æ­£ç‰ˆï¼‰
class AITuberStreamingSystem:
    """YouTubeãƒ©ã‚¤ãƒ–é…ä¿¡ç”¨AITuberã‚·ã‚¹ãƒ†ãƒ  v2.1 - ä¿®æ­£ç‰ˆ"""

    def __init__(self, config, character_id, character_manager, voice_manager, audio_player, log_callback):
        self.config = config
        self.character_id = character_id
        self.character_manager = character_manager
        self.voice_manager = voice_manager  # æ›´æ–°ã•ã‚ŒãŸéŸ³å£°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.audio_player = audio_player
        self.log = log_callback
        self.communication_logger = CommunicationLogger() # è¿½åŠ 

        # Google AI Studioè¨­å®šï¼ˆæ–‡ç« ç”Ÿæˆå°‚ç”¨ï¼‰
        api_key = self.config.get_system_setting("google_ai_api_key")

        if api_key:
            try:
                self.client = genai.Client(api_key=api_key) # Client ã‚’åˆæœŸåŒ–
            except Exception as e:
                self.client = None
                self.log(f"è­¦å‘Š: Google AI Clientã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            self.client = None
            self.log("è­¦å‘Š: Google AI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Google AIé–¢é€£æ©Ÿèƒ½ãŒå‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # YouTube APIè¨­å®š
        self.youtube_api_key = self.config.get_system_setting("youtube_api_key")
        self.youtube_base_url = "https://www.googleapis.com/youtube/v3"

        # çŠ¶æ…‹ç®¡ç†
        self.chat_id = None
        self.previous_comment = ""
        self.viewer_memory = {}
        self.running = False
        self.chat_history = [] # ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ

    async def _generate_response_local_llm_streaming(self, prompt_text: str, endpoint_url: str, char_name_for_log: str = "LocalLLMStream") -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆLM Studioæƒ³å®šï¼‰ã‹ã‚‰å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ç”¨)"""
        self.log(f"ğŸ¤– {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLM ({endpoint_url}) ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ­ã‚®ãƒ³ã‚°ã¯å‘¼ã³å‡ºã—å…ƒã® generate_response ã§è¡Œã†

        payload = {
            "model": "local-model",
            "messages": [{"role": "user", "content": prompt_text}],
            "temperature": 0.7,
            "max_tokens": 100
        }
        headers = {"Content-Type": "application/json"}
        generated_text = f"ãƒ­ãƒ¼ã‚«ãƒ«LLM ({endpoint_url}) å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ©ãƒ¼

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(endpoint_url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=60)) as response:
                    response_text_for_error = await response.text()
                    response.raise_for_status()
                    response_data = json.loads(response_text_for_error)

                    if response_data.get("choices") and isinstance(response_data["choices"], list) and len(response_data["choices"]) > 0:
                        message = response_data["choices"][0].get("message")
                        if message and isinstance(message, dict) and "content" in message:
                            generated_text = message["content"].strip()
                            self.log(f"ğŸ¤– {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‹ã‚‰ã®å¿œç­”å–å¾—æˆåŠŸã€‚")
                            return generated_text

                    self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”å½¢å¼ã‚¨ãƒ©ãƒ¼ã€‚Response: {response_data}")
                    generated_text = "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”å½¢å¼ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚"
        except aiohttp.ClientConnectorError as e:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMæ¥ç¶šã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e}")
            generated_text = f"ãƒ­ãƒ¼ã‚«ãƒ«LLM ({endpoint_url}) ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        except aiohttp.ClientResponseError as e:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLM APIã‚¨ãƒ©ãƒ¼ ({endpoint_url}) - Status: {e.status}, Message: {e.message}, Response: {response_text_for_error}")
            generated_text = f"ãƒ­ãƒ¼ã‚«ãƒ«LLM APIã‚¨ãƒ©ãƒ¼ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {e.status})ã€‚"
        except asyncio.TimeoutError:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({endpoint_url})ã€‚")
            generated_text = "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
        except json.JSONDecodeError as e_json:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã®JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e_json}. Response Text: {response_text_for_error}")
            generated_text = "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚’JSONè§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        except Exception as e_generic:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e_generic}\n{traceback.format_exc()}")
            # generated_text ã¯æ—¢ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¨­å®šæ¸ˆã¿
        return generated_text

    async def run_streaming(self, live_id):
        """é…ä¿¡ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        try:
            self.log("é…ä¿¡æº–å‚™ä¸­...")
            self.chat_id = await self.get_chat_id(live_id)
            if not self.chat_id:
                self.log("âŒ ãƒãƒ£ãƒƒãƒˆIDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é…ä¿¡ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã€‚")
                return

            self.log("âœ… YouTubeé…ä¿¡ã«æ¥ç¶šã—ã¾ã—ãŸ")
            self.running = True
            char_data = self.config.get_character(self.character_id)
            char_name = char_data.get('name', 'AIã¡ã‚ƒã‚“')
            self.log(f"ğŸŒŸ {char_name}ãŒé…ä¿¡é–‹å§‹ã—ã¾ã—ãŸï¼")

            while self.running:
                try:
                    comments = await self.get_latest_comments()
                    if comments:
                        latest_comment = comments[-1]
                        comment_text = latest_comment['snippet']['displayMessage']
                        author_name = latest_comment['authorDetails']['displayName']

                        if comment_text != self.previous_comment:
                            self.log(f"ğŸ’¬ {author_name}: {comment_text}")
                            response_text = await self.generate_response(comment_text, author_name)

                            if response_text:
                                self.log(f"ğŸ¤– {char_name}: {response_text}")
                                await self.synthesize_and_play(response_text)
                                history_length = self.config.get_system_setting("conversation_history_length", 0)
                                if history_length > 0:
                                    self.chat_history.append({"user": author_name, "comment": comment_text, "response": response_text})
                                    if len(self.chat_history) > history_length:
                                        self.chat_history.pop(0)
                            self.previous_comment = comment_text
                    await asyncio.sleep(self.config.get_system_setting("chat_monitor_interval", 5))
                except Exception as loop_e: # ãƒ«ãƒ¼ãƒ—å†…ã®ã‚¨ãƒ©ãƒ¼
                    self.log(f"âš ï¸ é…ä¿¡ãƒ«ãƒ¼ãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {loop_e}\n{traceback.format_exc()}")
                    await asyncio.sleep(10) # å°‘ã—å¾…ã£ã¦å†è©¦è¡Œ
        except Exception as main_e: # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®ã‚¨ãƒ©ãƒ¼
            self.log(f"âŒ é…ä¿¡å‡¦ç†å…¨ä½“ã§ã‚¨ãƒ©ãƒ¼: {main_e}\n{traceback.format_exc()}")
        finally:
            self.log("é…ä¿¡ã‚’çµ‚äº†ã—ã¾ã—ãŸ")

    async def get_chat_id(self, live_id):
        if not self.youtube_api_key:
            self.log("âŒ YouTube APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆIDã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
            return None
        try:
            url = f"{self.youtube_base_url}/videos"
            params = {'part': 'liveStreamingDetails', 'id': live_id, 'key': self.youtube_api_key}
            response = await asyncio.to_thread(requests.get, url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            if data.get('items'):
                return data['items'][0].get('liveStreamingDetails', {}).get('activeLiveChatId')
            return None
        except Exception as e:
            self.log(f"ãƒãƒ£ãƒƒãƒˆIDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    async def get_latest_comments(self, max_results=50):
        if not self.chat_id: return []
        if not self.youtube_api_key:
            self.log("âŒ YouTube APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
            return []
        try:
            url = f"{self.youtube_base_url}/liveChat/messages"
            params = {'liveChatId': self.chat_id, 'part': 'snippet,authorDetails', 'maxResults': max_results, 'key': self.youtube_api_key}
            response = await asyncio.to_thread(requests.get, url, params=params, timeout=10)
            response.raise_for_status()
            return response.json().get('items', [])
        except Exception as e:
            self.log(f"ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def generate_response(self, comment_text, author_name):
        char_name = self.config.get_character(self.character_id).get('name', 'AIã¡ã‚ƒã‚“')
        selected_model = self.config.get_system_setting("text_generation_model", "gemini-1.5-flash")
        ai_response_text = "ã”ã‚ã‚“ãªã•ã„ã€ã¡ã‚‡ã£ã¨è€ƒãˆä¸­ã§ã™ã€‚" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        try:
            char_prompt = self.character_manager.get_character_prompt(self.character_id)
            history_len = self.config.get_system_setting("conversation_history_length", 0)
            history_parts = [f"è¦–è´è€… {h['user']}: {h['comment']}\nã‚ãªãŸ: {h['response']}" for h in self.chat_history[-history_len:]] if history_len > 0 else []
            full_prompt = f"{char_prompt}\n\n{''.join(history_parts)}\n\nè¦–è´è€… {author_name}: {comment_text}\n\nè¦ªã—ã¿ã‚„ã™ãè‡ªç„¶ãªè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"

            self.communication_logger.add_log("sent", "text_generation", f"[Streaming to {char_name} (Model: {selected_model})]\n{full_prompt}")

            if selected_model == "local_lm_studio":
                local_llm_url = self.config.get_system_setting("local_llm_endpoint_url", "")
                if not local_llm_url:
                    ai_response_text = "ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLãŒæœªè¨­å®šã§ã™ã€‚"
                    self.log(f"âŒ LocalLLM (Streaming - {char_name}): ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLæœªè¨­å®šã€‚")
                else:
                    ai_response_text = await self._generate_response_local_llm_streaming(full_prompt, local_llm_url, char_name)
            else:
                if not self.client:
                    ai_response_text = "Google AIã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæœªåˆæœŸåŒ–)ã€‚"
                    self.log("âŒ Google AI ClientãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else:
                    gemini_response = await asyncio.to_thread(
                        self.client.models.generate_content,
                        model=selected_model, contents=full_prompt,
                        generation_config=genai.types.GenerateContentConfig(temperature=0.9, max_output_tokens=100, top_p=0.8)
                    )
                    ai_response_text = gemini_response.text.strip() if gemini_response.text else "ã†ãƒ¼ã‚“ã€ã†ã¾ãè¨€è‘‰ã«ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

            self.communication_logger.add_log("received", "text_generation", f"[Streaming from {char_name} (Model: {selected_model})]\n{ai_response_text}")
            return ai_response_text

        except genai.types.BlockedPromptException as bpe:
            ai_response_text = "ãã®å†…å®¹ã«ã¤ã„ã¦ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
            self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (Blocked): {bpe}")
            self.communication_logger.add_log("received", "text_generation", f"[Streaming from {char_name} (Model: {selected_model}) - Blocked]\n{bpe}")
        except requests.exceptions.HTTPError as http_err:
            ai_response_text = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({http_err.response.status_code})ã€‚"
            self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (HTTP): {http_err}")
            self.communication_logger.add_log("received", "text_generation", f"[Streaming from {char_name} (Model: {selected_model}) - HTTP Error {http_err.response.status_code}]\n{http_err}")
        except Exception as e:
            ai_response_text = "äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã§å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (Generic): {e}\n{traceback.format_exc()}")
            self.communication_logger.add_log("received", "text_generation", f"[Streaming from {char_name} (Model: {selected_model}) - Generic Error]\n{e}")
        return ai_response_text

    async def synthesize_and_play(self, text):
        try:
            char_data = self.config.get_character(self.character_id)
            char_name = char_data.get('name', 'AIã¡ã‚ƒã‚“')
            voice_settings = char_data.get('voice_settings', {})
            engine = voice_settings.get('engine', self.config.get_system_setting("voice_engine", "avis_speech")) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚¸ãƒ³è¨­å®š
            model = voice_settings.get('model') # ãƒ¢ãƒ‡ãƒ«ã¯ã‚¨ãƒ³ã‚¸ãƒ³ã”ã¨ã«ç•°ãªã‚‹ã®ã§ã€ã“ã“ã§ã¯Noneã‹ã‚‚ã—ã‚Œãªã„
            speed = voice_settings.get('speed', 1.0)

            self.communication_logger.add_log("sent", "voice_synthesis", f"[Streaming Voice for {char_name} (Engine: {engine}, Model: {model or 'N/A'})]\n{text}")

            google_api_key = self.config.get_system_setting("google_ai_api_key") if "google_ai_studio" in engine else None

            audio_files = await self.voice_manager.synthesize_with_fallback(
                text, model, speed, preferred_engine=engine, api_key=google_api_key
            )

            if audio_files:
                await self.audio_player.play_audio_files(audio_files)
            else:
                self.log(f"è­¦å‘Š: éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ ({char_name}, Text: '{text[:30]}...')")
        except Exception as e:
            self.log(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")

    def stop(self):
        self.running = False
        self.log("é…ä¿¡åœæ­¢å‡¦ç†ã‚’å‘¼ã³å‡ºã—ã¾ã—ãŸã€‚")
