"""
å®Œå…¨ç‰ˆ AITuberã‚·ã‚¹ãƒ†ãƒ  v2.2 - 4ã‚¨ãƒ³ã‚¸ãƒ³å®Œå…¨å¯¾å¿œç‰ˆï¼ˆæ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰
Google AI Studioæ–°éŸ³å£°åˆæˆï¼ˆ2025å¹´5æœˆè¿½åŠ ï¼‰+ Avis Speech + VOICEVOX + ã‚·ã‚¹ãƒ†ãƒ TTS

é‡è¦ãªè¿½åŠ :
- Google AI Studio æ–°éŸ³å£°åˆæˆAPIï¼ˆ2025å¹´5æœˆè¿½åŠ ï¼‰ã«å®Œå…¨å¯¾å¿œ
- æ—¢å­˜ã®å…¨æ©Ÿèƒ½ã‚’ç¶­æŒãƒ»æ‹¡å¼µï¼ˆæ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰
- 4ã¤ã®éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³å®Œå…¨çµ±åˆ
- å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã‚’4ã‚¨ãƒ³ã‚¸ãƒ³å¯¾å¿œã§å®Œå…¨å®Ÿè£…
- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã‚’4ã‚¨ãƒ³ã‚¸ãƒ³ã«å®Œå…¨æ‹¡å¼µ

æ©Ÿèƒ½ï¼ˆå…¨ã¦å®Œå…¨å®Ÿè£…ãƒ»æ©Ÿèƒ½å‰Šæ¸›ãªã—ï¼‰:
- 4ã¤ã®éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³çµ±åˆï¼ˆæœ€æ–°æŠ€è¡“å®Œå…¨å¯¾å¿œï¼‰
- å®Œå…¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
- è¤‡æ•°ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä½œæˆãƒ»ç·¨é›†ãƒ»ç®¡ç†ãƒ»è¤‡è£½ãƒ»å‰Šé™¤
- å®Œå…¨ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½
- YouTubeãƒ©ã‚¤ãƒ–å®Œå…¨é€£æº
- AIå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨å®Ÿè£…
- å®Œå…¨ç„¡æ–™ã€œãƒ—ãƒ­å“è³ªã¾ã§å…¨å¯¾å¿œ
"""

from config import ConfigManager
from character_manager import CharacterManager
from audio_manager import VoiceEngineManager, AudioPlayer

import tkinter as tk
from tkinter import ttk, messagebox, filedialog, simpledialog
from google import genai # å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¨å¥¨
from google.genai import types # å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¨å¥¨
#import google.generativeai as genai # ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
import requests
import asyncio
import json
import time
import os
import threading
import logging
import uuid
import webbrowser
import tempfile
#import subprocess
import platform
from datetime import datetime
from pathlib import Path
import aiohttp
#import urllib.parse
import base64
import wave # wave ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import re # æ­£è¦è¡¨ç¾ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import json # JSONãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (macOSãƒ‡ãƒã‚¤ã‚¹å–å¾—ã§ä½¿ç”¨)
import csv
import traceback # ã‚¨ãƒ©ãƒ¼è¿½è·¡ç”¨ã«è¿½åŠ 



# AITuberã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  v2.1ï¼ˆä¿®æ­£ç‰ˆï¼‰
class AITuberStreamingSystem:
    """YouTubeãƒ©ã‚¤ãƒ–é…ä¿¡ç”¨AITuberã‚·ã‚¹ãƒ†ãƒ  v2.1 - ä¿®æ­£ç‰ˆ"""
    
    def __init__(self, config, character_id, character_manager, voice_manager, audio_player, log_callback):
        self.config = config
        self.character_id = character_id
        self.character_manager = character_manager
        self.voice_manager = voice_manager  # æ›´æ–°ã•ã‚ŒãŸéŸ³å£°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.audio_player = audio_player
        self.log = log_callback
        
        # Google AI Studioè¨­å®šï¼ˆæ–‡ç« ç”Ÿæˆå°‚ç”¨ï¼‰
        api_key = self.config.get_system_setting("google_ai_api_key")
        # genai.configure(api_key=api_key) # ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã®ã¾ã¾
        # self.model = genai.GenerativeModel('gemini-2.5-flash') # æ—§æ–¹å¼
        self.client = genai.Client(api_key=api_key) # Client ã‚’åˆæœŸåŒ–ã—ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«æ ¼ç´
        
        # YouTube APIè¨­å®š
        self.youtube_api_key = self.config.get_system_setting("youtube_api_key")
        self.youtube_base_url = "https://www.googleapis.com/youtube/v3"
        
        # çŠ¶æ…‹ç®¡ç†
        self.chat_id = None
        self.previous_comment = ""
        self.viewer_memory = {}
        self.running = False
        self.chat_history = [] # ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        # self.available_gemini_models ã®å®šç¾©ã¨ã‚½ãƒ¼ãƒˆå‡¦ç†ã¯ AITuberMainGUI ã«ã‚ã‚‹ã¹ãã‚‚ã®ãªã®ã§ã€ã“ã“ã‹ã‚‰ã¯å®Œå…¨ã«å‰Šé™¤ã€‚

    async def _generate_response_local_llm_streaming(self, prompt_text: str, endpoint_url: str, char_name_for_log: str = "LocalLLMStream") -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆLM Studioæƒ³å®šï¼‰ã‹ã‚‰å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ç”¨)"""
        self.log(f"ğŸ¤– {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLM ({endpoint_url}) ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
        
        payload = {
            "model": "local-model", 
            "messages": [{"role": "user", "content": prompt_text}],
            "temperature": 0.7,
            "max_tokens": 100 # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨é€”ãªã®ã§çŸ­ã‚
        }
        headers = {"Content-Type": "application/json"}

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(endpoint_url, json=payload, headers=headers, timeout=aiohttp.ClientTimeout(total=60)) as response: # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«
                    response_text_for_error = await response.text() # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”¨ã«å…ˆèª­ã¿
                    response.raise_for_status()
                    
                    response_data = json.loads(response_text_for_error)
                    
                    if response_data.get("choices") and isinstance(response_data["choices"], list) and len(response_data["choices"]) > 0:
                        message = response_data["choices"][0].get("message")
                        if message and isinstance(message, dict) and "content" in message:
                            generated_text = message["content"].strip()
                            self.log(f"ğŸ¤– {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‹ã‚‰ã®å¿œç­”å–å¾—æˆåŠŸã€‚")
                            return generated_text
                    
                    self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”å½¢å¼ã‚¨ãƒ©ãƒ¼ã€‚Response: {response_data}")
                    return "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”å½¢å¼ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚"

        except aiohttp.ClientConnectorError as e:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMæ¥ç¶šã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e}")
            return f"ãƒ­ãƒ¼ã‚«ãƒ«LLM ({endpoint_url}) ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        except aiohttp.ClientResponseError as e:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLM APIã‚¨ãƒ©ãƒ¼ ({endpoint_url}) - Status: {e.status}, Message: {e.message}, Response: {response_text_for_error}")
            return f"ãƒ­ãƒ¼ã‚«ãƒ«LLM APIã‚¨ãƒ©ãƒ¼ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {e.status})ã€‚"
        except asyncio.TimeoutError: # aiohttp.ClientTimeout ã¯ asyncio.TimeoutError ã‚’ç™ºç”Ÿã•ã›ã‚‹
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({endpoint_url})ã€‚")
            return "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
        except json.JSONDecodeError as e_json: # json.loads() ãŒå¤±æ•—ã—ãŸå ´åˆ
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã®JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e_json}. Response Text: {response_text_for_error}")
            return "ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”ã‚’JSONè§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        except Exception as e_generic:
            self.log(f"âŒ {char_name_for_log}: ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ({endpoint_url}): {e_generic}\n{traceback.format_exc()}")
            return "ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã€‚"
    
    async def run_streaming(self, live_id):
        """é…ä¿¡ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        try:
            self.log("é…ä¿¡æº–å‚™ä¸­...")
            
            # ãƒãƒ£ãƒƒãƒˆIDå–å¾—
            self.chat_id = await self.get_chat_id(live_id)
            if not self.chat_id:
                self.log("âŒ ãƒãƒ£ãƒƒãƒˆIDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            
            self.log("âœ… YouTubeé…ä¿¡ã«æ¥ç¶šã—ã¾ã—ãŸ")
            self.running = True
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±å–å¾—
            char_data = self.config.get_character(self.character_id)
            char_name = char_data.get('name', 'AIã¡ã‚ƒã‚“')
            
            self.log(f"ğŸŒŸ {char_name}ãŒé…ä¿¡é–‹å§‹ã—ã¾ã—ãŸï¼")
            
            while self.running:
                try:
                    # ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—
                    comments = await self.get_latest_comments()
                    
                    if comments:
                        latest_comment = comments[-1]
                        comment_text = latest_comment['snippet']['displayMessage']
                        author_name = latest_comment['authorDetails']['displayName']
                        
                        # æ–°ã—ã„ã‚³ãƒ¡ãƒ³ãƒˆã®å ´åˆ
                        if comment_text != self.previous_comment:
                            self.log(f"ğŸ’¬ {author_name}: {comment_text}")
                            
                            # AIå¿œç­”ç”Ÿæˆï¼ˆæ–‡ç« ç”Ÿæˆã®ã¿ï¼‰
                            response = await self.generate_response(comment_text, author_name)
                            
                            if response:
                                self.log(f"ğŸ¤– {char_name}: {response}")
                                
                                # éŸ³å£°åˆæˆãƒ»å†ç”Ÿ
                                await self.synthesize_and_play(response)

                                # ä¼šè©±å±¥æ­´ã®è¨˜éŒ²ã¨ç®¡ç†
                                history_length = self.config.get_system_setting("conversation_history_length", 0)
                                if history_length > 0:
                                    # ç¾åœ¨ã®ã‚„ã‚Šå–ã‚Šã‚’å±¥æ­´ã«è¿½åŠ 
                                    self.chat_history.append({"user": author_name, "comment": comment_text, "response": response})
                                    # å±¥æ­´ãŒè¨­å®šã•ã‚ŒãŸé•·ã•ã‚’è¶…ãˆãŸå ´åˆã€æœ€ã‚‚å¤ã„ã‚‚ã®ã‹ã‚‰å‰Šé™¤
                                    if len(self.chat_history) > history_length:
                                        self.chat_history.pop(0)
                            
                            self.previous_comment = comment_text
                    
                    # ç›£è¦–é–“éš”
                    await asyncio.sleep(self.config.get_system_setting("chat_monitor_interval", 5)) # è¨­å®šã‹ã‚‰å–å¾—
                    
                except Exception as e:
                    self.log(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
                    await asyncio.sleep(10)
            
        except Exception as e:
            self.log(f"âŒ é…ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.log("é…ä¿¡ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    
    async def get_chat_id(self, live_id):
        """YouTubeãƒ©ã‚¤ãƒ–ã®ãƒãƒ£ãƒƒãƒˆIDå–å¾—"""
        try:
            url = f"{self.youtube_base_url}/videos"
            params = {
                'part': 'liveStreamingDetails',
                'id': live_id,
                'key': self.youtube_api_key
            }
            
            response = await asyncio.to_thread(requests.get, url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if 'items' in data and data['items']:
                live_details = data['items'][0].get('liveStreamingDetails', {})
                return live_details.get('activeLiveChatId')
            
            return None
            
        except Exception as e:
            self.log(f"ãƒãƒ£ãƒƒãƒˆIDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def get_latest_comments(self, max_results=50):
        """æœ€æ–°ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—"""
        if not self.chat_id:
            return []
        
        try:
            url = f"{self.youtube_base_url}/liveChat/messages"
            params = {
                'liveChatId': self.chat_id,
                'part': 'snippet,authorDetails',
                'maxResults': max_results,
                'key': self.youtube_api_key
            }
            
            response = await asyncio.to_thread(requests.get, url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            return data.get('items', [])
            
        except Exception as e:
            self.log(f"ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def generate_response(self, comment_text, author_name):
        """AIå¿œç­”ç”Ÿæˆï¼ˆæ–‡ç« ç”Ÿæˆå°‚ç”¨ï¼‰"""
        try:
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
            char_prompt = self.character_manager.get_character_prompt(self.character_id)
            
            # ä¼šè©±å±¥æ­´ã®é•·ã•ã‚’è¨­å®šã‹ã‚‰å–å¾—
            history_length = self.config.get_system_setting("conversation_history_length", 0)

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¼šè©±å±¥æ­´ã‚’çµ„ã¿è¾¼ã‚€
            history_prompt_parts = []
            if history_length > 0 and self.chat_history:
                # ç›´è¿‘ã®å±¥æ­´ã‚’å–å¾— (æœ€å¤§ history_length ä»¶)
                relevant_history = self.chat_history[-history_length:]
                for entry in relevant_history:
                    # å±¥æ­´ã®å„ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
                    history_prompt_parts.append(f"è¦–è´è€… {entry['user']}: {entry['comment']}")
                    history_prompt_parts.append(f"ã‚ãªãŸ: {entry['response']}") # AIè‡ªèº«ã®éå»ã®ç™ºè¨€ã¨ã—ã¦

            history_str = "\n".join(history_prompt_parts)
            # æœ€çµ‚çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š + ä¼šè©±å±¥æ­´ + æœ€æ–°ã®ã‚³ãƒ¡ãƒ³ãƒˆ
            full_prompt = f"{char_prompt}\n\n{history_str}\n\nè¦–è´è€… {author_name}: {comment_text}\n\nè¦ªã—ã¿ã‚„ã™ãè‡ªç„¶ãªè¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"
            
            # AIå¿œç­”ç”Ÿæˆï¼ˆæ–‡ç« ç”Ÿæˆã®ã¿ï¼‰
            selected_model_internal_name = self.config.get_system_setting("text_generation_model", "gemini-1.5-flash")
            local_llm_url = self.config.get_system_setting("local_llm_endpoint_url", "")
            char_name = self.config.get_character(self.character_id).get('name', 'AIã¡ã‚ƒã‚“') # ãƒ­ã‚°ç”¨

            if selected_model_internal_name == "local_lm_studio":
                if not local_llm_url:
                    self.log(f"âŒ LocalLLM (Streaming - {char_name}): ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    return "ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLãŒæœªè¨­å®šã§ã™ã€‚"
                # _generate_response_local_llm_streaming ã¯ await å¯èƒ½
                return await self._generate_response_local_llm_streaming(full_prompt, local_llm_url, char_name)
            else:
                # Google AI Studio (Gemini) ã‚’ä½¿ç”¨
                text_response = await asyncio.to_thread(
                    self.client.models.generate_content, # client ã‚’ä½¿ç”¨
                    model=selected_model_internal_name,  # è¨­å®šã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                    contents=full_prompt,
                    config=genai.types.GenerateContentConfig( 
                        temperature=0.9,
                        max_output_tokens=100, # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãªã®ã§çŸ­ã‚ã«
                        top_p=0.8
                    )
                )
                if text_response.text is None:
                    self.log(f"âš ï¸ AIå¿œç­”ãŒNoneã§ã—ãŸ (ãƒ¢ãƒ‡ãƒ«: {selected_model_internal_name})ã€‚")
                    return "ã”ã‚ã‚“ãªã•ã„ã€ã†ã¾ãè¨€è‘‰ãŒå‡ºã¦ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                return text_response.text.strip()
            
        except genai.types.generation_types.BlockedPromptException as bpe:
            self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚{bpe}")
            return "ã”ã‚ã‚“ãªã•ã„ã€ãã®å†…å®¹ã«ã¤ã„ã¦ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
        except requests.exceptions.HTTPError as http_err:
            if http_err.response.status_code == 429:
                self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: APIåˆ©ç”¨ä¸Šé™ã«é”ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ (429)ã€‚{http_err}")
                return "APIã®åˆ©ç”¨ä¸Šé™ã«é”ã—ãŸã¿ãŸã„ã§ã™ã€‚å°‘ã—æ™‚é–“ã‚’ãŠã„ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã­ã€‚"
            else:
                self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{http_err}")
                return "ã”ã‚ã‚“ãªã•ã„ã€ã‚µãƒ¼ãƒãƒ¼ã¨ã®é€šä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã¿ãŸã„ã§ã™ã€‚"
        except Exception as e:
            self.log(f"âŒ å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{e}")
            import traceback
            self.log(f"è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
            return "ã¡ã‚‡ã£ã¨èª¿å­ãŒæ‚ªã„ã¿ãŸã„ã§ã™ã€‚ã”ã‚ã‚“ãªã•ã„ã­ã€‚"
    
    async def synthesize_and_play(self, text):
        """éŸ³å£°åˆæˆãƒ»å†ç”Ÿ v2.1ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        try:
            char_data = self.config.get_character(self.character_id)
            voice_settings = char_data.get('voice_settings', {})
            voice_engine = voice_settings.get('engine', 'avis_speech')
            voice_model = voice_settings.get('model', 'Anneli(ãƒãƒ¼ãƒãƒ«)')
            speed = voice_settings.get('speed', 1.0)
            
            # API KEYå–å¾—ï¼ˆéŸ³å£°åˆæˆç”¨ï¼‰
            google_ai_api_key = self.config.get_system_setting("google_ai_api_key")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãéŸ³å£°åˆæˆ
            audio_files = await self.voice_manager.synthesize_with_fallback(
                text, voice_model, speed, preferred_engine=voice_engine, api_key=google_ai_api_key
            )
            
            if audio_files:
                # éŸ³å£°å†ç”Ÿ
                await self.audio_player.play_audio_files(audio_files)
            
        except Exception as e:
            self.log(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop(self):
        """é…ä¿¡åœæ­¢"""
        self.running = False
